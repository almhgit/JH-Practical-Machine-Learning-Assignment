#Practical Machine Learning - Weight Lifting Exercise Assignment

## By Anson


*The objective of this exercise is to identify a suitable machine learning algorithm to predict the manner an exercise was performed (the "classe")  the training set. This exercise will identify the variables to be used in the prediction model that will determine the outcome.*


*We will use the following steps to develop our machine learning algorithm*

*1.	Data Cleansing - Sanitize the datasets to remove unwanted or incomplete data sets*

*2.	Data Exploration - Understand the data variables and features available in the dataset provided*

*3.	Model selection - Identify potential models that are suitable based on the dataset characteristics *

*4.	Execute Models - Understand and compare results of the models to select the final model that will be used *

*5.	Testing - Utilize the selection prediction model to cross validate the testing set and understand the accuracy*



**Step 1: Obtain and cleanse the data**

*Obtain the data and load into the memory, and then set all values with "NA","#DIV/0!","" to NA in both the training and testing dataset*


```{R}
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

training <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))

dim(training)
dim(testing)

```

**Step 2: Load the relevant libraries and perform data exploration**
```{R}
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)

set.seed(12345)

```

*Partitioning the training dataset into "myTraining" and "myTesting" datasets based on 60% for training and 40% for testing*

```{R}
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]; myTesting <- training[-inTrain, ]
dim(myTraining); dim(myTesting)
```

**Step 3 : Perform transformation of the datasets to ensure that the model can be executed on both training and testing datasets**

```{R}
myTraining <- myTraining[c(-1)] # remove the index/ID column
```

```{R}
trainingV3 <- myTraining  #create subset to iterate in loop
for(i in 1:length(myTraining)) {  #for every column in the training dataset
  if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .6 ) {# if n?? NAs > 60% of total observations
    for(j in 1:length(trainingV3)) { #if the columns are the same:
       if( length( grep(names(myTraining[i]), names(trainingV3)[j]) ) ==1)
         trainingV3 <- trainingV3[ , -j] #Remove that column
    }
  }
}

dim(trainingV3) #To check the new number of observations

#Set back the myTraining dataset
myTraining <- trainingV3
rm(trainingV3)

```

*Now we will perform the transformation for myTesting and testing datasets*

```{R}
clean1 <- colnames(myTraining)
clean2 <- colnames(myTraining[, -59]) #already with classe column removed
myTesting <- myTesting[clean1]
testing <- testing[clean2]
dim(myTesting)

```

*Next to coerce the myTraining and the training datasets so that the models can be executed*

```{R}
for (i in 1:length(testing) ) {
  for(j in 1:length(myTraining)) {
         if( length( grep(names(myTraining[i]), names(testing)[j]) ) ==1)  {
             class(testing[j]) <- class(myTraining[i])
         }      
     }      
}
```
*Ensure the Coertion worked by : *
```{R}
testing <- rbind(myTraining[2, -59] , testing) #note row 2 does not mean anything, this will be removed right.. now:
testing <- testing[-1,]
dim(testing)
dim(myTesting)
dim(myTraining)
```

**Step 3 : Perform model selection by comparing Decision tree and Random Forest**
*Using the caret package, leverage the rpart function that calls the decision tree algorithm**

*Decision Tree*

```{R} 
modFit_DT <- rpart(classe ~ ., data=myTraining, method="class")
fancyRpartPlot(modFit_DT) 
predictions_DT <- predict(modFit_DT, myTesting, type = "class")
confusionMatrix(predictions_DT, myTesting$classe)

```
*Based on the result, the decision tree model from the caret package yields an accuracy of 0.8789*

*Now, we will use the random forest package to test the accuracy levels*

*Random Forest*
```{R}
modFit_RF <- randomForest(classe ~., data=myTraining)
predictions_RF <- predict(modFit_RF, myTesting, type = "class")
confusionMatrix(predictions_RF, myTesting$classe)
```

*Based on the result, the random forest model yields an accuracy of 0.9987. With these accuracy results, we can then proceed to perform the testing on the "testing" dataset*

**Step 4: Use the selected model (RandomForest) to perform the prediction on the testing dataset**

```{R}
predictions_Testing_DS <- predict(modFit_RF, testing, type = "class")
pml_write_files = function(x){
   n = length(x)
   for(i in 1:n){
     filename = paste0("problem_id_",i,".txt")
     write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
   }
 }
 
 pml_write_files(predictions_Testing_DS)
```


**Final Results on the testing dataset by the Random Forest Model**

* 1.B  2.A 3.B 4.A 5.A 6.E 7.D 8.B 9.A 10.A*

* 11.B 12.C 13.B 14.A 15.E 16.E 17.A 18.B 19.B 20.B*

**End of file**


